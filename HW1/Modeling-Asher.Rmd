#####Load Data

```{r}
trainingDataRaw <- read.csv(url("https://raw.githubusercontent.com/dsmilo/DATA621/master/HW1/data/moneyball-training-data.csv")) 
trainingDataRaw <- trainingDataRaw[,c(2:17)] # delete index
str(trainingDataRaw)
summary(trainingDataRaw)
```

#####Model 1

Description:

The dataset contains 17 columns - an index column (INDEX), a response column (TARGET_WINS) and 15 predictor columns. There are 2,276 observations - but there are many missing values for many of the predictors. 

Two predictors in particular stand out:

Predictor Name | Description | Impact | % Missing Values | Correlation Coefficient with Response | p-value
---|---|---|---|---|---|
TEAM_BATTING_HBP | Batters hit by pitch (get a free base) | Positive Impact on Wins | 91.6% | 7% | 31%
TEAM_BASERUN_CS | Strikeouts by batters | Negative Impact on Wins | 33.9% | 2% | 39%

Including these predictors in our dataset would mean that we would either have to a) forgo a significant chunk of our data (34% or 92%) or b) impute a large number of data points.  Their correlation coefficients with the response are less than an absolute value of 7%; the p values of a simple one variable linear regression using them and the response yields models of no statistical significance (i.e. p>0.05). Thus, it seems safe to exclude these predictors from our models. This way, we avoid the twin pitfalls of mass exclusion and imputation.

Relevant code for checking correlation coefficients and p values:

```{r}
dfraw <- read.csv(url("https://raw.githubusercontent.com/dsmilo/DATA621/master/HW1/data/moneyball-training-data.csv"))
dfHBP <- dfraw[!is.na(dfraw$TEAM_BATTING_HBP),] #Create df without null values for TEAM_BATTING_HBP
cor(dfHBP$TARGET_WINS,dfHBP$TEAM_BATTING_HBP)#Calculate correlation coefficient between response and TEAM_BATTING_HBP
summary(lm(TARGET_WINS~TEAM_BATTING_HBP, dfHBP))#See summary of linear regression model using TEAM_BATTING_HBP

dfCS <- dfraw[!is.na(dfraw$TEAM_BASERUN_CS),]#Create df without null values for TEAM_BASERUN_CS
cor(dfCS$TARGET_WINS,dfCS$TEAM_BASERUN_CS)#Calculate correlation coefficient between response and TEAM_BASERUN_CS
summary(lm(TARGET_WINS~TEAM_BASERUN_CS, dfCS))#See summary of linear regression model using TEAM_BASERUN_CS
```

Further exclusions to the data were made:

Exclusion | Explanation
|---|---|
TEAM_BATTING_SO = 0 | There's a gradient of strikeouts until 66, and then it goes directly to zero, which seems suspect



```{r}
dfraw <- read.csv(url("https://raw.githubusercontent.com/dsmilo/DATA621/master/HW1/data/moneyball-training-data.csv"))
dfremove <- subset(dfraw, TEAM_BATTING_SO == 0 | TEAM_PITCHING_SO == 0 | TEAM_BASERUN_SB == 0 | TEAM_BATTING_BB == 0 | TEAM_PITCHING_SO > 2500 | TEAM_PITCHING_BB == 0 )$INDEX #Identify rows for removal, have zero strikeouts or bases stolen
df <- subset(dfraw, !(INDEX %in% dfremove))
df <- df[, -c(1,10,11)] #Remove caught stealing and hit by pitcher variables
#View(df)
#View(df1)
summary(df)

df$TEAM_BATTING_HSO <- df$TEAM_BATTING_H/df$TEAM_BATTING_SO #Ratio of hits to strikeouts


fit1 <- lm(TARGET_WINS~.-TEAM_PITCHING_HR-TEAM_BATTING_SO-TEAM_BATTING_H, df)#Non-significant predictors removed
summary(fit1)
step1 <- step(fit1)
summary(step1)

#Correlation Matrix
View(round(cor(df1),2))

#These are variables that I tried but didn't turn out to be valuable
df1$TEAM_BATTING_1B <- df1$TEAM_BATTING_H - df1$TEAM_BATTING_2B - df1$TEAM_BATTING_3B - df1$TEAM_BATTING_HR #Singles - 1st Base Hits
df1$TEAM_BATTING_HRP <- df1$TEAM_BATTING_HR/df1$TEAM_BATTING_H #Home runs as a percentage of base hits
```

The number of missing values of "TEAM_BATTING_HBP"  is 2085.

#####Imputing Missing values
```{r}
library(mice)
tempData <- mice(trainingDataRaw,m=5,maxit=50,meth='pmm',seed=500)
summary(tempData)

new_data <- complete(tempData, 1)
summary(new_data)
View(cor(new_data))
```







#####Create a linear model using all predictors. The INDEX column is excluded.
FullModel <- lm(TARGET_WINS ~.-INDEX, trainingDataRaw)
summary(FullModel) #Summary of full model
#####Put full model through stepwise regression, where predictors with less significance are sequentially removed.
stepFull <- step(FullModel) 
summary(stepFull)

```{r}
#####Generate predictions using the stepFull model
predictionsStepFull <- predict(stepFull, trainingDataRaw) 
View(predictionsStepFull)
```

#####Generate the RMSE of the stepFull model
```{r}
rmseStep <- sqrt(mean((trainingDataRaw$TARGET_WINS[!is.na(predictionsStepFull)] - predictionsStepFull[!is.na(predictionsStepFull)])^2)) 
rmseStep
```

```{r}
par(mfrow=c(2,2)) #Set up a four panel plot for evaluating regression
plot(stepFull) #Displays Residuals vs Fitted, Scale-Location,  and Normal Q-Q.
```

#####Evaluation of Stepwise model without TEAM_BATTING_HBP
```{r}
ReducedModel <- lm(TARGET_WINS ~., trainingDataRaw[,c(2:10, 12:17)])
summary(ReducedModel)
stepReduced <- step(ReducedModel)
predictionsStepReduced <- predict(stepReduced, trainingDataRaw[,c(2:10, 12:17)])
rmseStepR <- sqrt(mean((trainingDataRaw$TARGET_WINS[!is.na(predictionsStepReduced)] - predictionsStepReduced[!is.na(predictionsStepReduced)])^2))
rmseStepR
```
